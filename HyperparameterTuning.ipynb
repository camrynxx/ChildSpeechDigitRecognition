{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d97f864",
   "metadata": {},
   "source": [
    "# Prediction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4b58ab",
   "metadata": {},
   "source": [
    "This file contains the code that tunes the hyperparameters for the k-NN, r-NN, and Entropy based confidence prediction methods.\n",
    "It also evaluates the performance of these models on different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddb570",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e05ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from os import path\n",
    "import os, glob, torch,torchaudio, re\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import sys\n",
    "import speech_dtw.qbe as qbe\n",
    "\n",
    "from transformers import WavLMModel\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(path.join(\"..\", \"utils\"))\n",
    "\n",
    "SAMPLE_RATE = 16000 \n",
    "WAVLM_LAYER_INDEX = 6\n",
    "\n",
    "device = \"cpu\"\n",
    "model = WavLMModel.from_pretrained(\"microsoft/wavlm-base-plus\").to(device).eval()\n",
    "\n",
    "def cmvn(X):\n",
    "    # X: [T, D] NumPy\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    sd = X.std(axis=0, keepdims=True)\n",
    "    return (X - mu) / (sd + 1e-8)\n",
    "\n",
    "def getWavLMFeatures(file): #A function which extracts MFCCs features from a given audio file\n",
    "    sig, rate = torchaudio.load(file) #Reads the audio file, extracting the sample rate and signal data (as an array)\n",
    "\n",
    "    #Check if sampled as correct sampling rate, if not - resample\n",
    "    if rate != SAMPLE_RATE:\n",
    "        print(\"Resampling\", file ,\"at 16kHz.\\n\")\n",
    "        sig = torchaudio.functional.resample(sig, rate, SAMPLE_RATE)\n",
    "\n",
    "    #Extracts layer 6 features\n",
    "    sig = sig.to(device)\n",
    "    with torch.inference_mode():\n",
    "        out = model(sig, output_hidden_states=True)\n",
    "        features = out.hidden_states[WAVLM_LAYER_INDEX].squeeze(0)  # [T, D] torch\n",
    "\n",
    "    #Convert to numpy\n",
    "    features = features.numpy()\n",
    "\n",
    "    #Apply CMVN\n",
    "    features = cmvn(features) #Applies cepstral mean and variance normalization to features\n",
    "    \n",
    "    return features\n",
    "\n",
    "def getMinimumCost(queryFile, templateFile, FeatureType):\n",
    "    #Loading the features\n",
    "    if FeatureType == \"MFCCs\":\n",
    "        queryFeatures = getMFCCsFeatures(queryFile) #Extract features for query data\n",
    "    elif FeatureType == \"WavLM\":\n",
    "        queryFeatures = getWavLMFeatures(queryFile) #Extract features for query data\n",
    "        \n",
    "    templateFeatures = torch.load(templateFile) #Load the template's feature file\n",
    "    templateFeatures = templateFeatures[\"features\"].numpy() #Extract the features as numpy arrays\n",
    "\n",
    "    #Make both feature sets 2D, float64, contiguous:\n",
    "    queryFeatures = np.ascontiguousarray(queryFeatures, dtype=np.float64)\n",
    "    templateFeatures = np.ascontiguousarray(templateFeatures, dtype=np.float64)\n",
    "\n",
    "    distance = qbe.dtw_sweep_min(queryFeatures, templateFeatures) #Calculate the minimum sweeping DTW distance between the two feature sets\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f366d85",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracies_knn(testFolder, templateFolder, ks):\n",
    "    correct = {k: 0 for k in ks}\n",
    "    total = 0\n",
    "    class_counts = Counter()\n",
    "    correct_per_class = {k: Counter() for k in ks}\n",
    "\n",
    "    # Load templates\n",
    "    template_files = list(Path(templateFolder).rglob(\"*.pt\"))\n",
    "    template_labels = {}\n",
    "    for temp in template_files:\n",
    "        parts = temp.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        if prefix.isdigit():\n",
    "            template_labels[str(temp)] = int(prefix)\n",
    "\n",
    "    for testFile in Path(testFolder).rglob(\"*.wav\"):\n",
    "        parts = testFile.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        true_label = int(prefix) if prefix.isdigit() else \"No Number\"\n",
    "        class_counts[true_label] += 1\n",
    "        total += 1\n",
    "\n",
    "        # Compute distances\n",
    "        distances = []\n",
    "        for temp_path in template_labels:\n",
    "            dist = getMinimumCost(str(testFile), temp_path, \"WavLM\")\n",
    "            distances.append((dist, template_labels[temp_path]))\n",
    "\n",
    "        # Sort\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "\n",
    "        # Evaluate for each k\n",
    "        for k in ks:\n",
    "            if k <= 0: continue\n",
    "            knn = distances[:k]\n",
    "            labels = [lab for d, lab in knn]\n",
    "            counts = Counter(labels)\n",
    "            predicted_label = counts.most_common(1)[0][0]\n",
    "            if predicted_label == true_label:\n",
    "                correct[k] += 1\n",
    "                correct_per_class[k][true_label] += 1\n",
    "\n",
    "    results = {}\n",
    "    for k in ks:\n",
    "        accuracy = (correct[k] / total) * 100 if total > 0 else 0.0\n",
    "        if k == 1:\n",
    "            print(f\"Classification Results for k=1:\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        results[k] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"class_counts\": dict(class_counts),\n",
    "            \"correct_per_class\": dict(correct_per_class[k])\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dfaae5",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6999041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "ks = list(range(1, 11))\n",
    "knnAccuracies = accuracies_knn(\"ValidationData/OnlyNumbers\",\n",
    "                               \"TrainingData/TrainingFeatures/WavLMBase+/English\",\n",
    "                               ks=ks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc61f17",
   "metadata": {},
   "source": [
    "## r-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_r(testFile, template_labels, r, true_label):\n",
    "    # Compute distances to all templates\n",
    "    distances = []\n",
    "    for temp_path, label in template_labels.items():\n",
    "        dist = getMinimumCost(str(testFile), temp_path, \"WavLM\")\n",
    "        distances.append((dist, label))\n",
    "\n",
    "    # Find all templates within radius r\n",
    "    rnn = [(d, lab) for d, lab in distances if d <= r]\n",
    "    \n",
    "    predicted_label = \"No Number\" if not rnn else Counter(lab for d, lab in rnn).most_common(1)[0][0]\n",
    "    \n",
    "    return true_label, predicted_label\n",
    "\n",
    "def evaluate_rnn_metrics(testFolder, templateFolder, r_values):\n",
    "    # Load all template files and their labels once\n",
    "    template_files = list(Path(templateFolder).rglob(\"*.pt\"))\n",
    "    template_labels = {}\n",
    "    for temp in template_files:\n",
    "        parts = temp.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        if prefix.isdigit():\n",
    "            template_labels[str(temp)] = int(prefix)\n",
    "\n",
    "    test_files = list(Path(testFolder).rglob(\"*.wav\"))\n",
    "    true_labels = []\n",
    "    for testFile in test_files:\n",
    "        parts = testFile.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        true_label = int(prefix) if prefix.isdigit() else \"No Number\"\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for r in r_values:\n",
    "            # Parallelize predictions for all test files\n",
    "            predictions = list(executor.map(\n",
    "                lambda tf: compute_metrics_for_r(tf, template_labels, r, true_labels[test_files.index(tf)]),\n",
    "                test_files\n",
    "            ))\n",
    "\n",
    "            # Calculate overall metrics\n",
    "            correct_predictions = 0\n",
    "            true_positives = 0\n",
    "            false_positives = 0\n",
    "            false_negatives = 0\n",
    "            true_negatives = 0\n",
    "            total = len(test_files)\n",
    "\n",
    "            for true_label, predicted_label in predictions:\n",
    "                # Accuracy: exact match (same number or \"No Number\")\n",
    "                if true_label == predicted_label:\n",
    "                    correct_predictions += 1\n",
    "                    if true_label != \"No Number\":\n",
    "                        true_positives += 1\n",
    "                    else:\n",
    "                        true_negatives += 1\n",
    "                else:\n",
    "                    if predicted_label != \"No Number\":\n",
    "                        false_positives += 1\n",
    "                    if true_label != \"No Number\":\n",
    "                        false_negatives += 1\n",
    "\n",
    "            accuracy = correct_predictions / total * 100 if total > 0 else 0.0\n",
    "            precision = true_positives / (true_positives + false_positives) * 100 if (true_positives + false_positives) > 0 else 0.0\n",
    "            recall = true_positives / (true_positives + false_negatives) * 100 if (true_positives + false_negatives) > 0 else 0.0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            # Print results for this r\n",
    "            print(f\"\\nResults for r={r}:\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            print(f\"Precision: {precision:.2f}%\")\n",
    "            print(f\"Recall: {recall:.2f}%\")\n",
    "            print(f\"F1 Score: {f1:.2f}%\")\n",
    "\n",
    "            results[r] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1\n",
    "            }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9dd086",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79aca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "evaluate_rnn_metrics(\"ValidationData/WithNoNumClass\", \"TrainingData/TrainingFeatures/WavLMBase+/English/\", np.arange(0.3, 0.45, 0.01) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80890111",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7827c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_for_entropy(testFile, template_labels, threshold, true_label):\n",
    "    # Compute min distances to each class (0-9)\n",
    "    min_dists = {lab: float('inf') for lab in range(10)}\n",
    "    for temp_path, label in template_labels.items():\n",
    "        dist = getMinimumCost(str(testFile), temp_path, \"WavLM\")\n",
    "        if dist < min_dists[label]:\n",
    "            min_dists[label] = dist\n",
    "\n",
    "    dists = [min_dists[i] for i in range(10)]\n",
    "    min_d = min(d for d in dists if d != float('inf'))\n",
    "    sims = [math.exp(-(d - min_d)) if d != float('inf') else 0 for d in dists]\n",
    "    sum_sim = sum(sims)\n",
    "    probs = [s / sum_sim if sum_sim > 0 else 0 for s in sims]\n",
    "\n",
    "    # Entropy\n",
    "    entropy = -sum(p * math.log(p) for p in probs if p > 0)\n",
    "\n",
    "    if entropy > threshold:\n",
    "        predicted_label = \"No Number\"\n",
    "    else:\n",
    "        best_class = dists.index(min(dists))\n",
    "        predicted_label = best_class\n",
    "    \n",
    "    return true_label, predicted_label\n",
    "\n",
    "def evaluate_entropy_metrics(testFolder, templateFolder, threshold_values):\n",
    "    # Load all template files and their labels once\n",
    "    template_files = list(Path(templateFolder).rglob(\"*.pt\"))\n",
    "    template_labels = {}\n",
    "    for temp in template_files:\n",
    "        parts = temp.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        if prefix.isdigit():\n",
    "            template_labels[str(temp)] = int(prefix)\n",
    "\n",
    "    test_files = list(Path(testFolder).rglob(\"*.wav\"))\n",
    "    true_labels = []\n",
    "    for testFile in test_files:\n",
    "        parts = testFile.stem.split(\"_\")\n",
    "        prefix = parts[0]\n",
    "        true_label = int(prefix) if prefix.isdigit() else \"No Number\"\n",
    "        true_labels.append(true_label)\n",
    "\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for threshold in threshold_values:\n",
    "            # Parallelize predictions for all test files\n",
    "            predictions = list(executor.map(\n",
    "                lambda tf: compute_metrics_for_entropy(tf, template_labels, threshold, true_labels[test_files.index(tf)]),\n",
    "                test_files\n",
    "            ))\n",
    "\n",
    "            # Calculate overall metrics\n",
    "            true_positives = 0\n",
    "            false_positives = 0\n",
    "            false_negatives = 0\n",
    "            true_negatives = 0\n",
    "            total = len(test_files)\n",
    "\n",
    "            for true_label, predicted_label in predictions:\n",
    "                is_true_number = true_label != \"No Number\"\n",
    "                is_pred_number = predicted_label != \"No Number\"\n",
    "                \n",
    "                if is_true_number and is_pred_number:\n",
    "                    true_positives += 1\n",
    "                elif is_true_number and not is_pred_number:\n",
    "                    false_negatives += 1\n",
    "                elif not is_true_number and is_pred_number:\n",
    "                    false_positives += 1\n",
    "                else:\n",
    "                    true_negatives += 1\n",
    "\n",
    "            accuracy = (true_positives + true_negatives) / total * 100 if total > 0 else 0.0\n",
    "            precision = true_positives / (true_positives + false_positives) * 100 if (true_positives + false_positives) > 0 else 0.0\n",
    "            recall = true_positives / (true_positives + false_negatives) * 100 if (true_positives + false_negatives) > 0 else 0.0\n",
    "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "            # Print results for this threshold\n",
    "            print(f\"\\nResults for threshold={threshold}:\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "            print(f\"Precision: {precision:.2f}%\")\n",
    "            print(f\"Recall: {recall:.2f}%\")\n",
    "            print(f\"F1 Score: {f1:.2f}%\")\n",
    "\n",
    "            results[threshold] = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"f1\": f1\n",
    "            }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72fcc1",
   "metadata": {},
   "source": [
    "Usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_entropy_metrics(\"ValidationData/WithNoNumClass\", \"TrainingData/TrainingFeatures/WavLMBase+/Child/Jibo\", np.arange(2.1, 2.6, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da8242",
   "metadata": {},
   "source": [
    "# Prediction Method Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722b0a17",
   "metadata": {},
   "source": [
    "Minimum Cost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6972661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "minCostValidationAccuracy = accuracies_knn(\"ValidationData/OnlyNumbers\",\n",
    "                               \"TrainingData/TrainingFeatures/WavLMBase+/English\",\n",
    "                               [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa99699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "minCostTestingAccuracy = accuracies_knn(\"TestingData/OnlyNumbers\",\n",
    "                               \"TrainingData/TrainingFeatures/WavLMBase+/English\",\n",
    "                               [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04278c18",
   "metadata": {},
   "source": [
    "k-NN with k=3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb891ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "knnValidationAccuracy = accuracies_knn(\"ValidationData/OnlyNumbers\",\n",
    "                               \"TrainingData/TrainingFeatures/WavLMBase+/English\",\n",
    "                               [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b680573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "knnTestingAccuracy = accuracies_knn(\"TestingData/OnlyNumbers\",\n",
    "                               \"TrainingData/TrainingFeatures/WavLMBase+/English\",\n",
    "                               [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afaf04f",
   "metadata": {},
   "source": [
    "r-NN with r=0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Data\n",
    "rnnValidationAccuracy = evaluate_rnn_metrics(\"ValidationData/WithNoNumClass\", \"TrainingData/TrainingFeatures/WavLMBase+/English/\", np.arange(0.36, 0.37, 0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f95ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Data\n",
    "rnnTestingAccuracy = evaluate_rnn_metrics(\"TestingData/WithNoNumClass\", \"TrainingData/TrainingFeatures/WavLMBase+/English/\", np.arange(0.36, 0.37, 0.01) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f527b2",
   "metadata": {},
   "source": [
    "# Final Prediction Function's Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5303ec2",
   "metadata": {},
   "source": [
    "English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30152984",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyEnglish =  accuracies_knn(\"TestingData/OnlyNumbers/English\", \"TrainingData/TrainingFeatures/WavLMBase+/Child/Jibo\", [3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb994e7",
   "metadata": {},
   "source": [
    "Afrikaans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyAfrikaans =  accuracies_knn(\"TestingData/OnlyNumbers/Afrikaans\", \"TrainingFeatures/WavLMBase+/Afrikaans\", [3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
